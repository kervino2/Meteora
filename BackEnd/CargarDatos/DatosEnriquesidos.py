import json
import re
from ddgs import DDGS
import requests
from bs4 import BeautifulSoup
import ollama
import os
import pandas as pd
import concurrent.futures
import textwrap

# -------------------------------------------------------------------
# Funciones auxiliares: b√∫squeda y scraping
# -------------------------------------------------------------------

def buscar_en_web(meteorito, num_resultados=3):
    """Busca informaci√≥n relevante en la web sobre un meteorito, 
    excluyendo resultados del dominio 'lpi.usra.edu'."""
    tema = f"{meteorito.get('name', '')} meteorite {meteorito.get('year', '')}".strip()
    print(f"\nüîç Buscando informaci√≥n sobre: {tema}\n")

    resultados = []
    texto_combinado = ""

    try:
        with DDGS() as ddgs:
            for r in ddgs.text(tema, max_results=num_resultados):
                url = r.get("href")
                titulo = r.get("title")
                descripcion = r.get("body")

                if not url:
                    continue

                # üîé Excluir resultados del dominio lpi.usra.edu
                if "lpi.usra.edu" in url:
                    print(f"‚è≠Ô∏è Ignorado (LPI): {url}")
                    continue

                try:
                    response = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
                    soup = BeautifulSoup(response.text, "html.parser")

                    # Eliminar etiquetas innecesarias
                    for tag in soup(["script", "style", "noscript"]):
                        tag.decompose()

                    contenido = " ".join(p.get_text() for p in soup.find_all("p"))
                    contenido = contenido.strip()[:5000]  # Limitar tama√±o

                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo extraer texto de {url}: {e}")
                    contenido = ""

                if contenido:  # Evitar a√±adir vac√≠os
                    resultados.append({
                        "titulo": titulo,
                        "url": url,
                        "descripcion": descripcion,
                        "contenido": contenido
                    })
                    texto_combinado += f"{titulo or ''}\n{descripcion or ''}\n{contenido}\n"

    except Exception as e:
        print(f"‚ö†Ô∏è Error durante la b√∫squeda: {e}")

    return {
        "resultados": resultados,
        "texto": texto_combinado.strip()
    }

def buscar_en_web_especial(meteorito, num_resultados=10):
    """
    Busca informaci√≥n m√°s completa en la web sobre un meteorito.
    Se ampl√≠a el n√∫mero de resultados y el texto extra√≠do de cada p√°gina.
    Excluye dominios no √∫tiles como 'lpi.usra.edu'.
    """
    tema = f"{meteorito.get('name', '')} meteorite {meteorito.get('year', '')}".strip()
    print(f"\nüîç Buscando informaci√≥n extendida sobre: {tema}\n")

    resultados = []
    texto_combinado = ""

    try:
        with DDGS() as ddgs:
            for r in ddgs.text(tema, max_results=num_resultados):
                url = r.get("href")
                titulo = r.get("title")
                descripcion = r.get("body")

                if not url:
                    continue
                if "lpi.usra.edu" in url or "wikipedia" in url.lower():
                    print(f"‚è≠Ô∏è Ignorado (fuente excluida): {url}")
                    continue

                try:
                    response = requests.get(url, timeout=12, headers={"User-Agent": "Mozilla/5.0"})
                    soup = BeautifulSoup(response.text, "html.parser")

                    # Limpieza del HTML
                    for tag in soup(["script", "style", "noscript", "footer", "header", "nav", "aside"]):
                        tag.decompose()

                    # Extraer texto principal
                    contenido = " ".join(p.get_text() for p in soup.find_all(["p", "article", "div", "main"]))
                    contenido = re.sub(r"\s+", " ", contenido).strip()

                    if len(contenido) > 10000:  # Limita el texto para evitar excesos
                        contenido = contenido[:10000]

                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo extraer texto de {url}: {e}")
                    contenido = ""

                if contenido:
                    resultados.append({
                        "titulo": titulo,
                        "url": url,
                        "descripcion": descripcion,
                        "contenido": contenido
                    })
                    texto_combinado += f"\n\n---\nFuente: {url}\n{titulo or ''}\n{descripcion or ''}\n{contenido}\n"

    except Exception as e:
        print(f"‚ö†Ô∏è Error durante la b√∫squeda: {e}")

    return {
        "resultados": resultados,
        "texto": texto_combinado.strip()
    }



def extraer_contenido(url):
    """Extrae el texto principal de una p√°gina web."""
    try:
        response = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(response.text, "html.parser")
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()
        texto = " ".join(p.get_text() for p in soup.find_all("p"))
        return texto[:3000]
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo extraer contenido de {url}: {e}")
        return ""


# -------------------------------------------------------------------
# Unir meteoritos y eventos (en memoria)
# -------------------------------------------------------------------

def unir_datos(meteoritos, eventos):
    coincidencias = []
    usados = set()  # IDs o √≠ndices de eventos NASA ya emparejados

    for m in meteoritos:
        match_encontrado = None
        min_distancia = float("inf")

        for idx, e in enumerate(eventos):
            # Calcular distancia geogr√°fica
            try:
                distancia = ((float(e["lat"]) - float(m["coordinadesLat"])) ** 2 +
                             (float(e["lon"]) - float(m["coordinadesLon"])) ** 2) ** 0.5
            except (ValueError, TypeError):
                continue

            # Coincidencia si est√° cerca y el a√±o concuerda
            try:
                if distancia < 0.5 and abs(int(e["date"][:4]) - int(m["Year"])) <= 1:
                    if distancia < min_distancia:
                        min_distancia = distancia
                        match_encontrado = e
                        match_idx = idx
            except (ValueError, TypeError):
                continue

        fotos_raw = m.get("fotos", "")
        fotos_limpias = []
        if isinstance(fotos_raw, str) and fotos_raw.strip():
            fotos_list = [f.strip() for f in fotos_raw.split(";") if f.strip()]
            for f in fotos_list:
                partes = [p.strip() for p in f.split("|")]
                fotos_limpias.append({
                    "autor": partes[0] if len(partes) > 0 else "Desconocido",
                    "referencia": partes[1] if len(partes) > 1 else "No especificado",
                    "link": partes[2] if len(partes) > 2 else "Sin enlace"
                })

        # Datos base
        data = {
            "name": m.get("Name", ""),
            "status": m.get("Status", ""),
            "fall": m.get("Fall", ""),
            "year": m.get("Year", ""),
            "place": m.get("Place", ""),
            "type": m.get("Type", ""),
            "mass": m.get("Mass", ""),
            "country": m.get("Country", ""),
            "basic_name": m.get("basic_name", ""),
            "basic_abbrev": m.get("basic_abbrev", ""),
            "basic_fall": m.get("basic_fall", ""),
            "basic_yearFound": m.get("basic_yearFound", ""),
            "basic_country": m.get("basic_country", ""),
            "classification": m.get("classification_recomend", ""),
            "coordinadesExact": m.get("coordinadesExact", ""),
            "coordinadesLat": m.get("coordinadesLat", ""),
            "coordinadesLon": m.get("coordinadesLon", ""),
            "coordinadesRecomend": m.get("coordinadesRecomend", ""),
            "coordinadesLatRecomend": m.get("coordinadesLatRecomend", ""),
            "coordinadesLonRecomend": m.get("coordinadesLonRecomend", ""),
            "dataMB109_Lat": m.get("DataMB109_Lat", ""),
            "dataMB109_Lon": m.get("DataMB109_Lon", ""),
            "dataMB109_Mass": m.get("DataMB109_Mass", ""),
            "dataMB109_Piece": m.get("DataMB109_Piece", ""),
            "dataMB109_Class": m.get("DataMB109_Class", ""),
            "dataMB109_Weathering": m.get("DataMB109_Weathering", ""),
            "dataMB109_Fayalite": m.get("DataMB109_Fayalite", ""),
            "dataMB109_Ferrosilite": m.get("DataMB109_Ferrosilite", ""),
            "dataMB109_Classifier": m.get("DataMB109_Classifier", ""),
            "dataMB109_Main_mass": m.get("DataMB109_Main_mass", ""),
            "dataMB109_Coments": m.get("DataMB109_Coments", ""),
            "impact_date": "",
            "impact_lat": "",
            "impact_lon": "",
            "impact_alt": "",
            "impact_vel": "",
            "impact_energy": "",
            "impact_e": "",
            "metBull_fotos": fotos_limpias,
        }

        # Si hay coincidencia NASA ‚Üí se completan campos
        if match_encontrado:
            data.update({
                "impact_date": match_encontrado.get("date", ""),
                "impact_lat": match_encontrado.get("lat", ""),
                "impact_lon": match_encontrado.get("lon", ""),
                "impact_alt": match_encontrado.get("alt", ""),
                "impact_vel": match_encontrado.get("vel", ""),
                "impact_energy": match_encontrado.get("energy", ""),
                "impact_e": match_encontrado.get("impact_e", ""),
            })
            usados.add(match_idx)

        coincidencias.append(data)

    # üîπ Agregar impactos NASA sin coincidencias
    sin_match = [e for i, e in enumerate(eventos) if i not in usados]
    for i, e in enumerate(sin_match, start=1):
        coincidencias.append({
            "name": f"Impacto {i}",
            "status": "Desconocido",
            "fall": "",
            "year": e.get("date", "")[:4] if e.get("date") else "",
            "place": "No identificado",
            "type": "",
            "mass": "",
            "country": "",
            "basic_name": "",
            "basic_abbrev": "",
            "basic_fall": "",
            "basic_yearFound": "",
            "basic_country": "",
            "classification": "No hay informaci√≥n",
            "coordinadesExact": "",
            "coordinadesLat": e.get("lat", ""),
            "coordinadesLon": e.get("lon", ""),
            "coordinadesRecomend": "",
            "coordinadesLatRecomend": "",
            "coordinadesLonRecomend": "",
            "dataMB109_Lat": "",
            "dataMB109_Lon": "",
            "dataMB109_Mass": "",
            "dataMB109_Piece": "",
            "dataMB109_Class": "",
            "dataMB109_Weathering": "",
            "dataMB109_Fayalite": "",
            "dataMB109_Ferrosilite": "",
            "dataMB109_Classifier": "",
            "dataMB109_Main_mass": "",
            "dataMB109_Coments": "Solo se tiene registro del impacto, sin meteorito asociado.",
            "impact_date": e.get("date", ""),
            "impact_lat": e.get("lat", ""),
            "impact_lon": e.get("lon", ""),
            "impact_alt": e.get("alt", ""),
            "impact_vel": e.get("vel", ""),
            "impact_energy": e.get("energy", ""),
            "impact_e": e.get("impact_e", ""),
            "metBull_fotos": [],
        })

    total = len(coincidencias)
    con_match = sum(1 for c in coincidencias if c["impact_date"])
    print(f"‚úÖ {total} registros procesados ‚Äî {con_match} con datos NASA (incluidos impactos sin meteorito)")

    return coincidencias


# -------------------------------------------------------------------
# Enriquecer datos con IA local
# -------------------------------------------------------------------

def parse_info_ia(texto):
    """Convierte la respuesta de la IA en un diccionario limpio sin campos vac√≠os ni valores 'No hay informaci√≥n'."""
    campos_validos = [
        "nombre", "historia", "importancia", "descubrimiento", "impacto",
        "velocidad (km/s)", "energ√≠a (kilotones)", "links", "fotos", "videos"
    ]

    datos = {}
    for linea in texto.splitlines():
        linea = linea.strip()
        if not linea or ":" not in linea:
            continue

        clave, valor = linea.split(":", 1)
        clave = clave.strip().lower()
        valor = valor.strip()

        # üßπ Evita incluir texto vac√≠o o sin informaci√≥n
        if clave in campos_validos and valor and valor.lower() not in ["no hay informaci√≥n", "no hay datos", "sin datos", "n/a"]:
            clave_final = f"ia_{clave.replace(' (km/s)', '').replace(' (kilotones)', '').replace(' ', '_')}"
            datos[clave_final] = valor
        elif clave in campos_validos:
            # Si existe el campo pero no hay valor √∫til ‚Üí lo deja vac√≠o
            clave_final = f"ia_{clave.replace(' (km/s)', '').replace(' (kilotones)', '').replace(' ', '_')}"
            datos[clave_final] = ""

    return datos

def obtener_datos_con_ia(meteorito, texto_web=""):
    """
    Genera informaci√≥n extendida de un meteorito usando Ollama (modelo llama3).
    Si un campo est√° vac√≠o, devuelve 'No hay informaci√≥n'.
    Asegura unidades est√°ndar y respuestas en espa√±ol.
    Si el meteorito ya tiene datos (por ejemplo fotos, videos), se conservan y se agregan nuevos.
    """

    if isinstance(meteorito, dict):
        name = meteorito.get("Name", "")
        year = meteorito.get("Year", "")
        lat = meteorito.get("coordinadesLat") or meteorito.get("DataMB109_Lat") or ""
        lon = meteorito.get("coordinadesLon") or meteorito.get("DataMB109_Lon") or ""
        mass = meteorito.get("Mass", "")
        country = meteorito.get("Country", "")
    else:
        name = str(meteorito)
        year = lat = lon = mass = country = ""

    prompt = f"""
Act√∫a como un investigador experto en meteoritos que habla en espa√±ol.
Tienes los siguientes datos base y, si existe, informaci√≥n web.
Debes generar informaci√≥n f√°cil de entender y clara sobre el meteorito en espa√±ol aunque puedes extenderte mas para darle mas sentido al parrafo o informaci√≥n.
En links pon todo lo que se uso que se considere referencia.

Usa unidades est√°ndar:
- Velocidad en km/s
- Energ√≠a en kilotones

Reglas:
- Si un dato no est√° disponible, escribe exactamente: "No hay informaci√≥n". Evitar explicar si no esta el dato o comcluciones
- No inventes informaci√≥n sin contexto.
- Usa los datos base si est√°n presentes (por ejemplo, si ya se da una masa, resp√©tala).
- Devuelve cada campo en una l√≠nea como se indica, sin comas ni comillas.


Formato de respuesta (l√≠nea por l√≠nea):

nombre:
historia:
importancia:
descubrimiento:
impacto:
velocidad (km/s):
energ√≠a (kilotones):
links:
fotos:
videos:

Texto de referencia:
{texto_web}

Datos base:
nombre: {name}
a√±o: {year}
masa: {mass}
pa√≠s: {country}
latitud: {lat}
longitud: {lon}
"""

    try:
        respuesta = ollama.chat(model="llama3", messages=[
            {"role": "user", "content": prompt}
        ])
        texto = respuesta["message"]["content"].strip()

        # Campos esperados
        campos = [
            "nombre", "historia", "importancia", "descubrimiento", "impacto",
            "velocidad (km/s)", "energ√≠a (kilotones)", "links", "fotos", "videos"
        ]

        resultado = {campo: "No hay informaci√≥n" for campo in campos}
        for linea in texto.splitlines():
            if ":" in linea:
                k, v = linea.split(":", 1)
                k = k.strip().lower()
                v = v.strip() or "No hay informaci√≥n"
                for campo in campos:
                    if campo.lower().startswith(k):
                        resultado[campo] = v
                        break

        # Mezclar resultados con datos existentes
        for campo, valor in resultado.items():
            clave_ia = f"ia_{campo.replace(' (km/s)', '').replace(' (kilotones)', '').replace(' ', '_')}"
            anterior = meteorito.get(clave_ia, "")

            # Si ya hab√≠a algo y es distinto de "No hay informaci√≥n", conservarlo y agregar nuevo contenido
            if anterior and anterior != "No hay informaci√≥n":
                if valor and valor != "No hay informaci√≥n" and valor not in anterior:
                    meteorito[clave_ia] = f"{anterior}\n{valor}"
            else:
                meteorito[clave_ia] = valor

        return meteorito

    except Exception as e:
        print("‚ö†Ô∏è Error con IA:", e)
        return meteorito



def parse_info_ia_especial(texto):
    """
    Convierte la respuesta de la IA en un diccionario limpio con todos los campos esperados.
    Evita incluir datos vac√≠os o gen√©ricos.
    """
    campos_validos = [
        "nombre", "historia", "importancia", "descubrimiento", "impacto",
        "velocidad (km/s)", "energ√≠a (kilotones)", "links", "fotos", "videos"
    ]

    datos = {}
    for campo in campos_validos:
        clave_final = f"ia_{campo.replace(' (km/s)', '').replace(' (kilotones)', '').replace(' ', '_')}"
        datos[clave_final] = ""  # inicializa todos los campos

    for linea in texto.splitlines():
        linea = linea.strip()
        if not linea or ":" not in linea:
            continue

        clave, valor = linea.split(":", 1)
        clave = clave.strip().lower()
        valor = valor.strip()

        if valor and valor.lower() not in ["no hay informaci√≥n", "no hay datos", "sin datos", "n/a"]:
            for campo in campos_validos:
                if campo.startswith(clave):
                    clave_final = f"ia_{campo.replace(' (km/s)', '').replace(' (kilotones)', '').replace(' ', '_')}"
                    datos[clave_final] = valor
                    break
    return datos


def obtener_datos_con_ia_especial(meteorito, texto_web=""):
    """
    Usa el modelo IA para generar informaci√≥n contextual extendida sobre el meteorito.
    Incluye datos de historia, origen, impacto, descubrimiento, noticias, etc.
    Devuelve todos los campos ia_* incluso si est√°n vac√≠os.
    """

    name = meteorito.get("Name", meteorito.get("name", ""))
    year = meteorito.get("Year", meteorito.get("year", ""))
    lat = meteorito.get("coordinadesLat") or meteorito.get("DataMB109_Lat") or ""
    lon = meteorito.get("coordinadesLon") or meteorito.get("DataMB109_Lon") or ""
    mass = meteorito.get("Mass", meteorito.get("dataMB109_Mass", ""))
    country = meteorito.get("Country", meteorito.get("basic_country", ""))
    tipo = meteorito.get("Type", meteorito.get("dataMB109_Class", ""))
    clasificacion = meteorito.get("classification_recomend", "")
    weathering = meteorito.get("dataMB109_Weathering", "")
    fayalite = meteorito.get("dataMB109_Fayalite", "")
    ferrosilite = meteorito.get("dataMB109_Ferrosilite", "")
    alt = meteorito.get("impact_alt", "")
    vel = meteorito.get("impact_vel", "")
    energia = meteorito.get("impact_energy", "")
    place = meteorito.get("Place", "")

    prompt = f"""
Eres un investigador experto en meteoritos, escribe en espa√±ol y con tono cient√≠fico-divulgativo.
Tu tarea es generar informaci√≥n completa y coherente sobre el meteorito con base en los datos y textos disponibles.

Enf√≥cate especialmente en:
- Historia y contexto del descubrimiento
- Impacto o consecuencias conocidas (geol√≥gicas, medi√°ticas o cient√≠ficas)
- Origen o tipo de meteorito
- Importancia y relevancia en la investigaci√≥n
- Noticias o referencias verificables (usa los enlaces o fuentes que aparezcan)

üìã Debes incluir **TODOS** los campos del formato, incluso si no hay datos (usa exactamente "No hay informaci√≥n").
No inventes informaci√≥n no sustentada.

Formato obligatorio de salida:
nombre:
historia:
importancia:
descubrimiento:
impacto:
velocidad (km/s):
energ√≠a (kilotones):
links:
fotos:
videos:

üìÑ Texto de referencia:
{texto_web[:15000]}

üìä Datos base:
nombre: {name}
a√±o: {year}
pa√≠s: {country}
lugar: {place}
tipo: {tipo}
clasificaci√≥n: {clasificacion}
masa: {mass}
latitud: {lat}
longitud: {lon}
altitud: {alt}
velocidad (si disponible): {vel}
energ√≠a estimada: {energia}
grado de meteorizaci√≥n: {weathering}
fayalita: {fayalite}
ferrosilita: {ferrosilite}
"""

    try:
        respuesta = ollama.chat(model="llama3", messages=[
            {"role": "user", "content": prompt}
        ])
        texto = respuesta["message"]["content"].strip()
        nuevos_datos = parse_info_ia_especial(texto)

        # Fusionar datos nuevos con los existentes sin perder nada
        for k, v in nuevos_datos.items():
            if not meteorito.get(k) or meteorito[k] in ["", "No hay informaci√≥n"]:
                meteorito[k] = v
            elif v and v not in meteorito[k]:
                meteorito[k] += f"\n{v}"

        return meteorito

    except Exception as e:
        print(f"‚ö†Ô∏è Error con IA especial: {e}")
        return meteorito

# -------------------------------------------------------------------
# Guardar a JSON 
# -------------------------------------------------------------------
def guardar_total(resultados, nombre="meteoritos.json"):
    """Guarda todos los resultados en un √∫nico archivo JSON, actualizando sin duplicar."""
    ruta = os.path.join(os.path.dirname(__file__), nombre)

    # Si ya existe, cargar y actualizar sin duplicados
    existentes = []
    if os.path.exists(ruta):
        try:
            with open(ruta, "r", encoding="utf-8") as f:
                existentes = json.load(f)
        except json.JSONDecodeError:
            existentes = []

    # Evita duplicar por nombre y a√±o
    existentes_dict = {(e.get("name"), e.get("year")): e for e in existentes}
    for r in resultados:
        existentes_dict[(r.get("name"), r.get("year"))] = r

    # Guardar versi√≥n actualizada
    with open(ruta, "w", encoding="utf-8") as f:
        json.dump(list(existentes_dict.values()), f, ensure_ascii=False, indent=2)

    print(f"üíæ Archivo actualizado: {len(existentes_dict)} meteoritos guardados.")


def cargar_total(nombre="meteoritos.json"):
    """Carga los datos ya procesados si existen."""
    ruta = os.path.join(os.path.dirname(__file__), nombre)
    if os.path.exists(ruta):
        with open(ruta, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


# -------------------------------------------------------------------
# Procesamiento general
# -------------------------------------------------------------------


def texto_contiene_palabras_clave(texto, nombre_meteorito=None):
    """
    Eval√∫a si el texto contiene informaci√≥n relevante sobre el meteorito:
    historia, impacto, energ√≠a, velocidad, consecuencias o descubrimiento t√©cnico.
    Tambi√©n valida si el nombre del meteorito aparece en el t√≠tulo o cuerpo del texto.
    Retorna True si vale la pena procesarlo con IA.
    """

    if not texto or len(texto.strip()) < 100:
        return False  # texto demasiado corto ‚Üí probablemente irrelevante

    texto = texto.lower()
    nombre_meteorito = (nombre_meteorito or "").lower().strip()

    # ‚ö°Ô∏è Frases clave o contextos importantes
    patrones_relevantes = [
        # --- Impacto f√≠sico / ambiental / consecuencias ---
        r"(impact(ed|ing)?|cause(d)? (a )?(damage|change|shock|event|fire|explosion|impact)|"
        r"impact (area|zone|site)|impact effect|blast wave|crater formation|"
        r"released energy|energy of impact|impact velocity|entry velocity|angle of impact|"
        r"impact magnitude|airburst|collision energy)",

        # --- Historia / origen / descubrimiento ---
        r"(discovered in|was discovered|originated from|formed in|composition of|parent body|source asteroid|"
        r"was part of|fragmented from|classified as|recovered in|meteorite classification|"
        r"scientists (believe|suggest)|studies (show|indicate)|analysis revealed)",

        # --- Datos cient√≠ficos ---
        r"(velocity of|speed of entry|temperature reached|pressure impact|shock stage|"
        r"kinetic energy|mass of the meteorite|density|fusion crust|matrix|chondrules|"
        r"chemical composition|structure|grain size|surface features|melting point)",

        # --- Importancia o contexto hist√≥rico ---
        r"(news report|witnessed event|documented fall|reported by|observed fall|"
        r"impact caused|caused panic|injured|destroyed|hit the ground|"
        r"economic impact|affected the region|changed the landscape)"
    ]

    # üö´ Contenido irrelevante (com√∫n en tiendas o p√°ginas gen√©ricas)
    patrones_irrelevantes = [
        r"(found in|located in|coordinates|latitude|longitude|"
        r"copyright|newsletter|subscribe|buy|price|store|shop|review|discount|"
        r"collection|museum piece|sold by|available for sale)"
    ]

    # Si hay demasiados t√©rminos irrelevantes ‚Üí descartar
    if sum(bool(re.search(p, texto)) for p in patrones_irrelevantes) >= 2:
        return False

    # Contar coincidencias relevantes (por grupos de contexto)
    coincidencias = sum(bool(re.search(p, texto)) for p in patrones_relevantes)

    # üìç Validar si el nombre del meteorito aparece (exacto o parcial)
    nombre_presente = False
    if nombre_meteorito:
        # coincidencia exacta o parcial (por ejemplo "Abadla" en "Abadla 002")
        patron_nombre = re.escape(nombre_meteorito.split()[0])
        if re.search(rf"\b{patron_nombre}\b", texto):
            nombre_presente = True

        # si aparece al principio del texto o en may√∫sculas repetidas ‚Üí m√°s peso
        primeros_300 = texto[:300]
        if re.search(rf"\b{patron_nombre}\b", primeros_300):
            coincidencias += 1
            nombre_presente = True

    # üîç Regla final de decisi√≥n
    # - Requiere al menos 2 coincidencias relevantes
    # - Y el nombre debe estar mencionado de alguna forma
    if coincidencias >= 2 and nombre_presente:
        return True
    else:
        return False


def iniciar_procesamiento(meteoritos, eventos, filtros_personales=None):
    """
    Controla todo el flujo de procesamiento:
    1. Filtra por criterios autom√°ticos y manuales.
    2. Guarda vac√≠os los que no cumplen.
    3. Procesa con IA los que s√≠ cumplen o los marcados manualmente.
    """

    print("\nüöÄ Iniciando procesamiento general...\n")

    # -------------------------------
    # üîπ Unir los datos base
    # -------------------------------
    coincidencias = unir_datos(meteoritos, eventos)
    print(f"üîç Total de coincidencias unidas: {len(coincidencias)}")

    # -------------------------------
    # üîπ Filtro autom√°tico (criterios b√°sicos)
    # -------------------------------
    df = pd.DataFrame(coincidencias)
    df["Mass_num"] = df["mass"].apply(
        lambda x: float(x) if str(x).replace(".", "", 1).isdigit() else 0
    )
    df["Year_num"] = df["year"].apply(
        lambda y: int(y) if str(y).isdigit() else 0
    )

    df["Mass_num"] = pd.to_numeric(df.get("mass", 0), errors="coerce").fillna(0)

    # Determinar si tiene fotos
    df["tiene_fotos"] = df["metBull_fotos"].apply(lambda fotos: bool(fotos and len(fotos) > 0))

    # Aplicar criterios:
    # - Masa >= 3000 g
    # - Tiene al menos una foto
    cumple_criterios = df[
        (df["Mass_num"] >= 4000) | (df["tiene_fotos"])
    ].to_dict(orient="records")

    # Los que no cumplen (impactos sin coincidencia o datos limitados)
    no_cumple = df[~df.index.isin(
        [df.index[df["name"] == c["name"]][0] for c in cumple_criterios]
    )].to_dict(orient="records")

    print(f"üßÆ Cumplen criterios: {len(cumple_criterios)} | No cumplen: {len(no_cumple)}")

    # -------------------------------
    # üîπ Filtro personal (lista manual)
    # -------------------------------
    especiales = []
    if filtros_personales:
        palabras = [p.lower() for p in filtros_personales]
        especiales = [c for c in coincidencias if any(p in c["name"].lower() for p in palabras)]
        print(f"üéØ Meteoritos marcados manualmente: {len(especiales)}")
    else:
        print("‚ÑπÔ∏è No se definieron filtros personales.")

    # -------------------------------
    # üîπ Procesar seg√∫n el tipo
    # -------------------------------
    #print("\n‚öôÔ∏è Guardando meteoritos que no cumplen (solo estructura vac√≠a)...")
    #procesar_datos(no_cumple, eventos, tipo="vacios")

    #print("\n‚öôÔ∏è Procesando meteoritos que cumplen criterios autom√°ticos...")
    #procesar_datos(cumple_criterios, eventos, tipo="criterios")


    print("\n‚öôÔ∏è Procesando meteoritos con procesamiento especial...")
    procesar_datos(especiales, eventos, tipo="especiales")

    print("\n‚úÖ Proceso general completado.\n")


def procesar_datos(meteoritos, eventos, tipo="criterios", max_workers=8):
    """
    Procesa meteoritos seg√∫n su tipo:
      - 'criterios': cumplen condiciones, se procesan con IA.
      - 'vacios': no cumplen, solo se guardan con campos vac√≠os.
      - 'especiales': se procesar√°n distinto (por ahora igual que criterios, luego lo afinamos).
    """

    procesados = cargar_total()
    nombres_procesados = {(p.get("name"), p.get("year")) for p in procesados}
    campos_ia_base = [
        "ia_nombre", "ia_historia", "ia_importancia", "ia_descubrimiento", "ia_impacto",
        "ia_velocidad", "ia_energia", "ia_links", "ia_fotos", "ia_videos"
    ]

    nuevos_resultados = []

    def procesar_uno(c):
        try:
            if (c.get("name"), c.get("year")) in nombres_procesados:
                return None

            fusionado = c.copy()

            # -------------------------------
            # üß© Si es tipo VAC√çO ‚Üí guardar sin b√∫squeda
            # -------------------------------
            if tipo == "vacios":
                print(f"‚è© Guardado vac√≠o: {c['name']} ({c['year']})")
                for campo in campos_ia_base:
                    fusionado[campo] = ""
                return fusionado

            # -------------------------------
            # üåç Si cumple criterios ‚Üí buscar web y procesar IA
            # -------------------------------
            if tipo == "criterios" or tipo == "especiales":
                print(f"\nü™ê Procesando: {c['name']} ({c['year']})")
                busqueda = buscar_en_web(c)
                texto_web = busqueda["texto"]

                if texto_contiene_palabras_clave(texto_web, c.get("name")):
                    print(f"ü§ñ Analizando con IA...\n")
                    c_actualizado = obtener_datos_con_ia(c, texto_web)

                    info_ia_campos = parse_info_ia(
                        "\n".join(f"{k}: {v}" for k, v in c_actualizado.items() if k.startswith("ia_"))
                    )

                    fusionado.update(info_ia_campos)
                else:
                    print(f"‚è© Omitido IA (texto no relevante)")
                    for campo in campos_ia_base:
                        fusionado[campo] = ""

                # Asegurar estructura uniforme
                for campo in campos_ia_base:
                    fusionado.setdefault(campo, "")

                return fusionado

        except Exception as e:
            print(f"‚ö†Ô∏è Error al procesar {c.get('name')}: {e}")
            return None

    # -------------------------------
    # üßµ Ejecuci√≥n paralela
    # -------------------------------
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        for resultado in executor.map(procesar_uno, meteoritos):
            if resultado:
                nuevos_resultados.append(resultado)
                if len(nuevos_resultados) % 10 == 0:
                    guardar_total(nuevos_resultados)
                    nuevos_resultados = []

    if nuevos_resultados:
        guardar_total(nuevos_resultados)

    print(f"\n‚úÖ Procesamiento tipo '{tipo}' completado.\n")

# -------------------------------------------------------------------
# Uso
# -------------------------------------------------------------------

def leer_csv_a_lista(ruta):
    """Lee un CSV y lo convierte en una lista de diccionarios, evitando warnings por tipos mixtos."""
    if not os.path.exists(ruta):
        print(f"‚ö†Ô∏è No se encontr√≥ el archivo: {ruta}")
        return []
    try:
        df = pd.read_csv(ruta, low_memory=False, dtype=str)  # fuerza todo a texto
        return df.fillna("").to_dict(orient="records")
    except Exception as e:
        print(f"‚ö†Ô∏è Error leyendo CSV {ruta}: {e}")
        return []




if __name__ == "__main__":
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, "data")

    # Rutas de los CSV
    meteoritos_path = os.path.join(data_dir, "meteoritos_Metbull.csv")
    eventos_path = os.path.join(data_dir, "meteoritos_NasaCNEOS.csv")

    # Cargar datos desde los CSV
    meteorito = leer_csv_a_lista(meteoritos_path)
    eventos = leer_csv_a_lista(eventos_path)
    filtros_personales = ["Canyon Diablo","Ali","Willamette", "Winchcombe", "Fukang", "Hoba","Gancedo","El Chaco","Ahnighito","Bacubirito","Tunguska","Cheli√°binsk","Barringer","Chicxulub","Sikhote-Alin","Allende","Mbozi","Bacubirito","Armanty","Ahnighito"]

    resultados = iniciar_procesamiento(meteorito, eventos, filtros_personales)
